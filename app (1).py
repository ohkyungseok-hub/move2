import streamlit as st
import pandas as pd
import re
import time
import zipfile
from io import BytesIO
from pathlib import Path
from openpyxl import load_workbook

# =========================
# Settings
# =========================
DETAIL_LIMIT = 9
DEFAULT_CHUNK = 100
DEFAULT_OUT_SHEET_INDEX = 0
DEFAULT_ID_COL = "A"  # AíŒŒì¼ ìƒí’ˆì•„ì´ë”” ê¸°ë³¸ê°’(í•„ìš”ì‹œ ì‚¬ì´ë“œë°”ì—ì„œ ë³€ê²½)

# =========================
# Utils
# =========================
def col_idx(col: str) -> int:
    idx = 0
    for c in col.upper():
        idx = idx * 26 + (ord(c) - ord("A") + 1)
    return idx - 1


def uniq_keep_order(seq):
    return list(dict.fromkeys(seq))


def extract_bracket_items(val):
    """
    - [ ... ] ë¸”ë¡ ì—¬ëŸ¬ ê°œë©´ ê°ê° ì¶”ì¶œ
    - ë¸”ë¡ ë‚´ë¶€ ì½¤ë§ˆ ìˆìœ¼ë©´ ì¶”ê°€ ë¶„ë¦¬
    - ëŒ€ê´„í˜¸ ì—†ìœ¼ë©´ ì½¤ë§ˆ ë¶„ë¦¬ í´ë°±
    """
    if pd.isna(val):
        return []
    s = str(val).strip()
    if not s:
        return []

    blocks = re.findall(r"\[([^\]]+)\]", s)
    items = []

    if blocks:
        for blk in blocks:
            blk = blk.strip()
            if not blk:
                continue
            if "," in blk:
                items.extend([p.strip() for p in blk.split(",") if p.strip()])
            else:
                items.append(blk)
    else:
        s2 = s.replace("[", "").replace("]", "").strip()
        if not s2:
            return []
        items = [p.strip() for p in s2.split(",") if p.strip()]

    return items


def build_aw_cell(main_items, detail_items):
    """
    AW ì…€ = main + detail_1~detail_9 ë¥¼ ì¤„ë°”ê¿ˆ(Alt+Enter)ë¡œ í•œ ì…€ì— ì €ì¥
    """
    lines = []
    if main_items:
        lines.append(f"main^|^https://m.lastorder.in/{main_items[0]}")
    for i, it in enumerate(detail_items[:DETAIL_LIMIT], start=1):
        lines.append(f"detail_{i}^|^https://m.lastorder.in/{it}")
    return "\n".join(lines)


def validate_a_df(a: pd.DataFrame, id_col_letter: str):
    """
    ìƒˆ ê·œì¹™ì—ì„œ í•„ìš”í•œ A ì»¬ëŸ¼:
    C, D(ìƒí’ˆëª…), E(ì˜µì…˜ê°’), H, J, M(ì¬ê³ ), P(íŒë§¤ì¢…ë£Œì¼), S(main ì´ë¯¸ì§€), T(detail ì´ë¯¸ì§€), + ìƒí’ˆì•„ì´ë””
    """
    required = ["C", "D", "E", "H", "J", "M", "P", "S", "T", id_col_letter]
    max_needed = max(col_idx(c) for c in required)
    if a.shape[1] <= max_needed:
        missing = [c for c in required if col_idx(c) >= a.shape[1]]
        return False, f"AíŒŒì¼ ì»¬ëŸ¼ ë¶€ì¡±: {missing} (í˜„ì¬ ì»¬ëŸ¼ ìˆ˜: {a.shape[1]})"
    return True, ""


def split_rows(rows: list[dict], chunk_size: int):
    return [rows[i:i + chunk_size] for i in range(0, len(rows), chunk_size)] or [[]]


def apply_rows_to_template(template_bytes: bytes, rows: list[dict], sheet_index: int, start_row: int = 2):
    """
    b.xlsx í…œí”Œë¦¿(ì „ì²´ ì‹œíŠ¸/íƒ­ ìœ ì§€)ì— rowsë¥¼ sheet_index ì‹œíŠ¸ start_rowë¶€í„° ê°’ìœ¼ë¡œ ê¸°ì…
    """
    wb = load_workbook(BytesIO(template_bytes))
    ws = wb.worksheets[sheet_index]

    for i, row in enumerate(rows):
        excel_row = start_row + i
        for col_letter, val in row.items():
            ws[f"{col_letter}{excel_row}"] = val

    out = BytesIO()
    wb.save(out)
    out.seek(0)
    return out.getvalue()


# =========================
# Core transform (FINAL RULES)
# =========================
def make_b_rows_from_a(a: pd.DataFrame, id_col_letter: str):
    """
    âœ… ìµœì¢… ê·œì¹™

    B ë§¤í•‘:
    - A = 1
    - B = 217089
    - C = 1011307
    - G = A:D (ìƒí’ˆëª…)
    - J = 'n'
    - M = íŒë§¤ì¢…ë£Œì¼(P) ìˆìœ¼ë©´ 2 / ì—†ìœ¼ë©´ 1   (ì˜µì…˜ê·¸ë£¹ì€ ê·¸ë£¹ ìµœì†Œ ê¸°ì¤€)
    - O = Pê°’, ì—†ìœ¼ë©´ 2999-12-31              (ì˜µì…˜ê·¸ë£¹ì€ ê·¸ë£¹ ìµœì†Œ)
    - S = A:H
    - T = (A:H - A:J) ê³„ì‚° ê²°ê³¼ + "-1" ë¬¸ìì—´
    - AP = Pì—ì„œ ë‚ ì§œë§Œ (ì˜µì…˜ê·¸ë£¹ì€ ê·¸ë£¹ ìµœì†Œì˜ ë‚ ì§œ)
    - AR, AS = A:C
    - AW = ì´ë¯¸ì§€: main + detail_1~9 (ì¤„ë°”ê¿ˆ)
           main: A:Sì—ì„œ ì²« ì´ë¯¸ì§€
           detail: A:Tì—ì„œ ì¶”ì¶œ â†’ ì¤‘ë³µ ì œê±° â†’ 1~9
           ì˜µì…˜ê·¸ë£¹ì€ ê·¸ë£¹ ì „ì²´ í•©ì³ ì¤‘ë³µ ì œê±°

    ì˜µì…˜ê·¸ë£¹(ìƒí’ˆì•„ì´ë”” ì¤‘ë³µ):
    - AB = 'y'
    - AC = 'ì„ íƒ'
    - AD = ì˜µì…˜ê°’(A:E) ^|^ ì—°ê²° (ì¤‘ë³µ ì œê±°, ë“±ì¥ìˆœ)
    - AG = ì˜µì…˜ì¬ê³ (A:M)  (AD ì˜µì…˜ ìˆœì„œì— ë§ì¶° ^|^ ì—°ê²°)
    """

    # ìƒí’ˆì•„ì´ë””
    pid = a.iloc[:, col_idx(id_col_letter)].astype(str).fillna("").str.strip()
    is_dup = pid.duplicated(keep=False)
    option_pids = set(pid[is_dup])

    # ëŒ€í‘œí–‰(ê° pid ì²« í–‰) â€” ì¸ë±ìŠ¤ resetìœ¼ë¡œ ë§¤ì¹­ ë’¤í‹€ë¦¼ ë°©ì§€
    rep_mask = ~pid.duplicated(keep="first")
    a_rep = a.loc[rep_mask].reset_index(drop=True)
    pid_rep = pid.loc[rep_mask].reset_index(drop=True)

    # ê·¸ë£¹ ìµœì†Œ íŒë§¤ì¢…ë£Œì¼
    p_all_dt = pd.to_datetime(a.iloc[:, col_idx("P")], errors="coerce")
    p_min_map = p_all_dt.groupby(pid).min()

    # ì˜µì…˜ê°’(E) (ì¤‘ë³µ ì œê±°, ë“±ì¥ ìˆœ) -> AD
    e_series = a.iloc[:, col_idx("E")]
    opt_value_map = (
        pd.DataFrame({"pid": pid, "opt": e_series})
        .groupby("pid", sort=False)["opt"]
        .apply(lambda s: "^|^".join(
            uniq_keep_order([str(v).strip() for v in s.tolist() if pd.notna(v) and str(v).strip()])
        ))
        .to_dict()
    )

    # ì˜µì…˜ì¬ê³ (M) -> AG (ì˜µì…˜ê°’ ìˆœì„œì— ë§ì¶° ë§¤ì¹­í•´ì„œ ^|^)
    m_stock_series = a.iloc[:, col_idx("M")]
    df_opt = pd.DataFrame({"pid": pid, "opt": e_series, "stk": m_stock_series})

    opt_stock_map = {}
    for pid_val, grp in df_opt.groupby("pid", sort=False):
        opt_vals_raw = [str(v).strip() for v in grp["opt"].tolist() if pd.notna(v) and str(v).strip()]
        opt_vals = uniq_keep_order(opt_vals_raw)

        stocks_out = []
        for ov in opt_vals:
            sub = grp.loc[grp["opt"].astype(str).str.strip() == ov, "stk"]
            chosen = ""
            for sv in sub.tolist():
                if pd.isna(sv):
                    continue
                ss = str(sv).strip()
                if ss and ss.lower() != "nan":
                    chosen = ss
                    break
            stocks_out.append(chosen)

        opt_stock_map[pid_val] = "^|^".join(stocks_out)

    # ì´ë¯¸ì§€ ê·¸ë£¹ í•©ì¹˜ê¸°
    s_img = a.iloc[:, col_idx("S")]
    t_img = a.iloc[:, col_idx("T")]

    def group_images(pid_value: str):
        mask = (pid == pid_value).to_numpy()

        # main: Sì—ì„œ ì²« ìœ íš¨ ì•„ì´í…œ 1ê°œ
        main_candidates = []
        for sv in s_img[mask]:
            main_candidates.extend(extract_bracket_items(sv))
        main_candidates = [x for x in main_candidates if x]

        # detail: Tì—ì„œ ì „ì²´ í•©ì³ ì¤‘ë³µ ì œê±°
        detail_candidates = []
        for tv in t_img[mask]:
            detail_candidates.extend(extract_bracket_items(tv))
        detail_candidates = uniq_keep_order([x for x in detail_candidates if x])

        return main_candidates, detail_candidates

    out_rows = []

    # ìˆ«ìê³„ì‚°ìš© (ëŒ€í‘œí–‰ ê¸°ì¤€)
    h_num = pd.to_numeric(a_rep.iloc[:, col_idx("H")], errors="coerce").fillna(0).to_numpy()
    j_num = pd.to_numeric(a_rep.iloc[:, col_idx("J")], errors="coerce").fillna(0).to_numpy()

    for i in range(len(a_rep)):
        pid_i = pid_rep.iloc[i]
        is_option = pid_i in option_pids

        row = {}

        # ê³ ì •
        row["A"] = 1
        row["B"] = 217089
        row["C"] = 1011307
        row["J"] = "n"

        # ìƒí’ˆëª…
        row["G"] = a_rep.iloc[:, col_idx("D")].to_numpy()[i]

        # S = A:H
        row["S"] = a_rep.iloc[:, col_idx("H")].to_numpy()[i]

        # T = (H - J) + "-1"
        row["T"] = f"{int(h_num[i] - j_num[i])}-1"

        # AR / AS = A:C
        c_val = a_rep.iloc[:, col_idx("C")].to_numpy()[i]
        row["AR"] = c_val
        row["AS"] = c_val

        # íŒë§¤ì¢…ë£Œì¼: ê·¸ë£¹ ìµœì†Œê°’
        pmin = p_min_map.get(pid_i, pd.NaT)
        if pd.isna(pmin):
            row["M"] = 1
            row["O"] = "2999-12-31"
            row["AP"] = "2999-12-31"
        else:
            d = pd.Timestamp(pmin).strftime("%Y-%m-%d")
            row["M"] = 2
            row["O"] = d
            row["AP"] = d

        # ì´ë¯¸ì§€ AW (ì˜µì…˜ì´ë“  ì•„ë‹ˆë“  group_images ì‚¬ìš©)
        main_items, detail_items = group_images(pid_i)
        row["AW"] = build_aw_cell(main_items, detail_items)

        # ì˜µì…˜ ì²˜ë¦¬
        if is_option:
            row["AB"] = "y"
            row["AC"] = "ì„ íƒ"
            row["AD"] = opt_value_map.get(pid_i, "")
            row["AG"] = opt_stock_map.get(pid_i, "")
        else:
            # ë¹„ì˜µì…˜ ì¬ê³ ë„ AGì— ë‹¨ì¼ Mê°’ì„ ë„£ê³  ì‹¶ë‹¤ë©´ ì•„ë˜ ì£¼ì„ì„ í•´ì œí•˜ì„¸ìš”.
            # ìš”êµ¬ì‚¬í•­ì€ "ì˜µì…˜ì¬ê³ "ì´ë¯€ë¡œ ê¸°ë³¸ì€ ë¹„ì›Œë‘¡ë‹ˆë‹¤.
            # row["AG"] = a_rep.iloc[:, col_idx("M")].to_numpy()[i]
            pass

        out_rows.append(row)

    return out_rows


# =========================
# Streamlit UI
# =========================
st.set_page_config(page_title="Aâ†’B ë³€í™˜ê¸°(ìµœì¢…)", layout="wide")
st.title("ğŸ“¦ AíŒŒì¼ â†’ Bí…œí”Œë¦¿(b.xlsx) ìë™ ë³€í™˜ê¸° (ìµœì¢…ë³¸)")

with st.expander("ì‚¬ìš© ë°©ë²•", expanded=True):
    st.write(
        "1) **B í…œí”Œë¦¿(b.xlsx)** ì—…ë¡œë“œ\n"
        "2) **A íŒŒì¼ ì—¬ëŸ¬ ê°œ** ì—…ë¡œë“œ(í´ë”ì²˜ëŸ¼ ë“œë˜ê·¸&ë“œë¡­ ê°€ëŠ¥)\n"
        "3) ë³€í™˜ ì‹œì‘ â†’ ê²°ê³¼ ZIP ë‹¤ìš´ë¡œë“œ\n\n"
        "- í…œí”Œë¦¿ì˜ **ëª¨ë“  ì‹œíŠ¸(ì•„ë˜ íƒ­) ìœ ì§€**\n"
        "- ì§€ì •í•œ ì‹œíŠ¸(ê¸°ë³¸ 0ë²ˆì§¸)ì— **2í–‰ë¶€í„° ê°’ë§Œ ì±„ì›€**\n"
        "- ì˜µì…˜ê·¸ë£¹ì€ ìƒí’ˆì•„ì´ë”” ì¤‘ë³µìœ¼ë¡œ íŒë‹¨í•˜ì—¬ **1í–‰ìœ¼ë¡œ ë¬¶ìŒ**\n"
    )

st.sidebar.header("ì„¤ì •")
id_col_letter = st.sidebar.text_input("AíŒŒì¼ ìƒí’ˆì•„ì´ë”” ì»¬ëŸ¼(ì—‘ì…€ ë¬¸ì)", value=DEFAULT_ID_COL).strip().upper()
chunk_size = st.sidebar.number_input("ë¶„í•  ì €ì¥(í–‰)", min_value=10, max_value=5000, value=DEFAULT_CHUNK, step=10)
sheet_index = st.sidebar.number_input("í…œí”Œë¦¿ì— ì“¸ ì‹œíŠ¸ ì¸ë±ìŠ¤(0=ì²« ì‹œíŠ¸)", min_value=0, max_value=30, value=DEFAULT_OUT_SHEET_INDEX, step=1)

template_file = st.file_uploader("B í…œí”Œë¦¿(b.xlsx) ì—…ë¡œë“œ", type=["xlsx"])
a_files = st.file_uploader("AíŒŒì¼ ì—…ë¡œë“œ(ì—¬ëŸ¬ ê°œ ê°€ëŠ¥)", type=["xlsx"], accept_multiple_files=True)

run_btn = st.button("ğŸš€ ë³€í™˜ ì‹œì‘", disabled=(template_file is None or not a_files))

if run_btn:
    t0 = time.time()
    st.info("ì²˜ë¦¬ ì¤‘...")

    template_bytes = template_file.getvalue()

    summary_rows = []
    error_rows = []

    zip_buf = BytesIO()
    with zipfile.ZipFile(zip_buf, "w", zipfile.ZIP_DEFLATED) as zf:
        for uf in a_files:
            if uf.name.startswith("~$"):
                continue

            started = time.time()
            status = "OK"
            msg = ""
            input_rows = 0
            out_files = 0

            try:
                a_df = pd.read_excel(uf)
                input_rows = len(a_df)

                ok, vmsg = validate_a_df(a_df, id_col_letter)
                if not ok:
                    raise ValueError(vmsg)

                rows = make_b_rows_from_a(a_df, id_col_letter)

                chunks = split_rows(rows, int(chunk_size))
                for idx, chunk in enumerate(chunks, start=1):
                    out_xlsx = apply_rows_to_template(
                        template_bytes=template_bytes,
                        rows=chunk,
                        sheet_index=int(sheet_index),
                        start_row=2
                    )
                    out_name = f"{Path(uf.name).stem}_part{idx:03d}.xlsx"
                    zf.writestr(out_name, out_xlsx)
                    out_files += 1

            except Exception as e:
                status = "FAIL"
                msg = str(e)
                error_rows.append({"file": uf.name, "reason": msg})

            elapsed = round(time.time() - started, 3)
            summary_rows.append({
                "file": uf.name,
                "status": status,
                "input_rows": input_rows,
                "output_files": out_files,
                "seconds": elapsed,
                "message": msg
            })

        # ë¦¬í¬íŠ¸ ì €ì¥
        summary_df = pd.DataFrame(summary_rows)
        zf.writestr("summary_report.csv", summary_df.to_csv(index=False).encode("utf-8-sig"))

        if error_rows:
            errors_df = pd.DataFrame(error_rows)
            zf.writestr("errors.csv", errors_df.to_csv(index=False).encode("utf-8-sig"))

    zip_buf.seek(0)
    total_sec = round(time.time() - t0, 2)

    st.success(f"âœ… ì™„ë£Œ! ì´ ì†Œìš” {total_sec}s")
    st.subheader("ğŸ“Š ìš”ì•½ ë¦¬í¬íŠ¸")
    st.dataframe(pd.DataFrame(summary_rows), use_container_width=True)

    if error_rows:
        st.subheader("âš ï¸ ì—ëŸ¬")
        st.dataframe(pd.DataFrame(error_rows), use_container_width=True)

    st.download_button(
        "ğŸ“¦ ê²°ê³¼ ZIP ë‹¤ìš´ë¡œë“œ (ì—‘ì…€ + ë¦¬í¬íŠ¸ í¬í•¨)",
        data=zip_buf,
        file_name="B_result.zip",
        mime="application/zip"
    )
