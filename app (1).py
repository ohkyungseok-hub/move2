import streamlit as st
import pandas as pd
import re
import time
import zipfile
from io import BytesIO
from pathlib import Path
from openpyxl import load_workbook

# =========================
# Settings
# =========================
DETAIL_LIMIT = 9
DEFAULT_CHUNK = 100
DEFAULT_OUT_SHEET_INDEX = 0
DEFAULT_ID_COL = "A"  # AíŒŒì¼ ìƒí’ˆì•„ì´ë”” ê¸°ë³¸ê°’(í•„ìš”ì‹œ ì‚¬ì´ë“œë°”ì—ì„œ ë³€ê²½)

# b í…œí”Œë¦¿ì—ì„œ ì‚­ì œí•  í–‰(ì—‘ì…€ ê¸°ì¤€): 1,3,4,5,6 ì‚­ì œ / 2í–‰(ì»¬ëŸ¼ëª…) ìœ ì§€
ROWS_TO_DELETE_1BASED = [1, 3, 4, 5, 6]


# =========================
# Utils
# =========================
def col_idx(col: str) -> int:
    idx = 0
    for c in col.upper():
        idx = idx * 26 + (ord(c) - ord("A") + 1)
    return idx - 1


def uniq_keep_order(seq):
    return list(dict.fromkeys(seq))


def extract_bracket_items(val):
    if pd.isna(val):
        return []
    s = str(val).strip()
    if not s:
        return []

    blocks = re.findall(r"\[([^\]]+)\]", s)
    items = []

    if blocks:
        for blk in blocks:
            blk = blk.strip()
            if not blk:
                continue
            if "," in blk:
                items.extend([p.strip() for p in blk.split(",") if p.strip()])
            else:
                items.append(blk)
    else:
        s2 = s.replace("[", "").replace("]", "").strip()
        if not s2:
            return []
        items = [p.strip() for p in s2.split(",") if p.strip()]

    return items


def build_aw_cell(main_items, detail_items):
    lines = []
    if main_items:
        lines.append(f"main^|^https://m.lastorder.in/{main_items[0]}")
    for i, it in enumerate(detail_items[:DETAIL_LIMIT], start=1):
        lines.append(f"detail_{i}^|^https://m.lastorder.in/{it}")
    return "\n".join(lines)


def validate_a_df(a: pd.DataFrame, id_col_letter: str):
    # í•„ìš”í•œ Aì»¬ëŸ¼: C,D,E,H,J,M,P,S,T + ìƒí’ˆì•„ì´ë””
    required = ["C", "D", "E", "H", "J", "M", "P", "S", "T", id_col_letter]
    max_needed = max(col_idx(c) for c in required)
    if a.shape[1] <= max_needed:
        missing = [c for c in required if col_idx(c) >= a.shape[1]]
        return False, f"AíŒŒì¼ ì»¬ëŸ¼ ë¶€ì¡±: {missing} (í˜„ì¬ ì»¬ëŸ¼ ìˆ˜: {a.shape[1]})"
    return True, ""


def split_rows(rows: list[dict], chunk_size: int):
    return [rows[i:i + chunk_size] for i in range(0, len(rows), chunk_size)] or [[]]


def get_template_bytes(optional_uploaded):
    """
    1ìˆœìœ„: ì—…ë¡œë“œ í…œí”Œë¦¿(ì„ íƒ)
    2ìˆœìœ„: app(1).pyì™€ ê°™ì€ í´ë”ì˜ b.xlsx
    """
    if optional_uploaded is not None:
        return optional_uploaded.getvalue()

    local_path = Path("b.xlsx")
    if local_path.exists():
        return local_path.read_bytes()

    raise FileNotFoundError(
        "b.xlsx í…œí”Œë¦¿ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. "
        "app(1).pyì™€ ê°™ì€ í´ë”ì— b.xlsxë¥¼ ë‘ê±°ë‚˜, í…œí”Œë¦¿ì„ ì—…ë¡œë“œí•˜ì„¸ìš”."
    )


def apply_rows_to_template(template_bytes: bytes, rows: list[dict], sheet_index: int, start_row_after_header: int = 2):
    """
    - í…œí”Œë¦¿ì˜ ëª¨ë“  íƒ­(ì‹œíŠ¸) ìœ ì§€
    - ì§€ì • ì‹œíŠ¸(sheet_index)ì—ì„œë§Œ:
        1) 1,3,4,5,6í–‰ ì‚­ì œ (2í–‰=ì»¬ëŸ¼ëª… ìœ ì§€)
        2) 'ì»¬ëŸ¼ëª… í–‰' ë°”ë¡œ ì•„ë˜(start_row_after_header)ë¶€í„° rows ê¸°ì…

    ì¤‘ìš”:
    - í–‰ ì‚­ì œ í›„ì—ëŠ” ì—‘ì…€ í–‰ ë²ˆí˜¸ê°€ ë‹¹ê²¨ì§€ë¯€ë¡œ,
      ì—¬ê¸°ì„œëŠ” "ì»¬ëŸ¼ëª…ì€ ë‚¨ëŠ”ë‹¤"ë§Œ ë³´ì¥í•˜ê³ ,
      ë°ì´í„°ëŠ” 'ì»¬ëŸ¼ëª… ì•„ë˜'ë¡œ ë„£ê¸° ìœ„í•´ start_row_after_header=2ë¡œ ê³ ì •í•©ë‹ˆë‹¤.
    """
    wb = load_workbook(BytesIO(template_bytes))
    ws = wb.worksheets[sheet_index]

    # âœ… í° ë²ˆí˜¸ë¶€í„° ì‚­ì œí•´ì•¼ ì¸ë±ìŠ¤ ê¼¬ì„ì´ ì—†ìŒ
    for r in sorted(ROWS_TO_DELETE_1BASED, reverse=True):
        if r == 2:
            continue
        ws.delete_rows(r, 1)

    # âœ… ì»¬ëŸ¼ëª…(ì›ë˜ 2í–‰)ì´ ë‚¨ì•„ìˆê³ , ì‚­ì œë¡œ ì¸í•´ ë³´í†µ 1í–‰ì´ ë¨
    # ê·¸ë˜ì„œ "ì»¬ëŸ¼ëª… ì•„ë˜"ì¸ 2í–‰ë¶€í„° ì…ë ¥
    start_row = start_row_after_header

    for i, row in enumerate(rows):
        excel_row = start_row + i
        for col_letter, val in row.items():
            ws[f"{col_letter}{excel_row}"] = val

    out = BytesIO()
    wb.save(out)
    out.seek(0)
    return out.getvalue()


# =========================
# Core transform (FINAL RULES + NEW CHANGES)
# =========================
def make_b_rows_from_a(a: pd.DataFrame, id_col_letter: str):
    """
    B ë§¤í•‘:
    - A = 1
    - B = 217089
    - C = 1011307
    - G = A:D (ìƒí’ˆëª…)
    - J = 'n'
    - M = íŒë§¤ì¢…ë£Œì¼(P) ìˆìœ¼ë©´ 2 / ì—†ìœ¼ë©´ 1 (ì˜µì…˜ê·¸ë£¹ì€ ê·¸ë£¹ ìµœì†Œ ê¸°ì¤€)
    - O = Pê°’, ì—†ìœ¼ë©´ 2999-12-31 (ì˜µì…˜ê·¸ë£¹ì€ ê·¸ë£¹ ìµœì†Œ)
    - S = A:H
    - T = (A:H - A:J) ê²°ê³¼ + "-1"
    - W = (ë¹„ì˜µì…˜ ì¬ê³ ) A:M
    - AG = (ì˜µì…˜ì¬ê³ ) A:M ì„ ì˜µì…˜ê°’ ìˆœì„œëŒ€ë¡œ ^|^
    - AP = ìœ íš¨ì¼ì(ë‚ ì§œë§Œ): Pê°€ ì—†ìœ¼ë©´ ë¹ˆì¹¸("")
    - AU = í•­ìƒ ë¹ˆì¹¸("")
    - AR, AS = A:C (Cê°€ ì—†ìœ¼ë©´ ë¹ˆì¹¸)
    - AW = ì´ë¯¸ì§€(main + detail_1~9 ì¤„ë°”ê¿ˆ) ì˜µì…˜ê·¸ë£¹ì€ ì „ì²´ í•©ì³ ì¤‘ë³µ ì œê±°

    ì˜µì…˜ê·¸ë£¹:
    - AB='y', AC='ì„ íƒ', AD=ì˜µì…˜ê°’(E)^|^
    """

    pid = a.iloc[:, col_idx(id_col_letter)].astype(str).fillna("").str.strip()
    is_dup = pid.duplicated(keep=False)
    option_pids = set(pid[is_dup])

    # ëŒ€í‘œí–‰(ê° pid ì²« í–‰)
    rep_mask = ~pid.duplicated(keep="first")
    a_rep = a.loc[rep_mask].reset_index(drop=True)
    pid_rep = pid.loc[rep_mask].reset_index(drop=True)

    # ê·¸ë£¹ ìµœì†Œ íŒë§¤ì¢…ë£Œì¼
    p_all_dt = pd.to_datetime(a.iloc[:, col_idx("P")], errors="coerce")
    p_min_map = p_all_dt.groupby(pid).min()

    # ì˜µì…˜ê°’(E) -> AD
    e_series = a.iloc[:, col_idx("E")]
    opt_value_map = (
        pd.DataFrame({"pid": pid, "opt": e_series})
        .groupby("pid", sort=False)["opt"]
        .apply(lambda s: "^|^".join(
            uniq_keep_order([str(v).strip() for v in s.tolist() if pd.notna(v) and str(v).strip()])
        ))
        .to_dict()
    )

    # ì˜µì…˜ì¬ê³ (M) -> AG (ì˜µì…˜ê°’ ìˆœì„œì— ë§ì¶° ^|^)
    m_stock_series = a.iloc[:, col_idx("M")]
    df_opt = pd.DataFrame({"pid": pid, "opt": e_series, "stk": m_stock_series})

    opt_stock_map = {}
    for pid_val, grp in df_opt.groupby("pid", sort=False):
        opt_vals_raw = [str(v).strip() for v in grp["opt"].tolist() if pd.notna(v) and str(v).strip()]
        opt_vals = uniq_keep_order(opt_vals_raw)

        stocks_out = []
        for ov in opt_vals:
            sub = grp.loc[grp["opt"].astype(str).str.strip() == ov, "stk"]
            chosen = ""
            for sv in sub.tolist():
                if pd.isna(sv):
                    continue
                ss = str(sv).strip()
                if ss and ss.lower() != "nan":
                    chosen = ss
                    break
            stocks_out.append(chosen)

        opt_stock_map[pid_val] = "^|^".join(stocks_out)

    # ì´ë¯¸ì§€ ê·¸ë£¹ í•©ì¹˜ê¸°
    s_img = a.iloc[:, col_idx("S")]
    t_img = a.iloc[:, col_idx("T")]

    def group_images(pid_value: str):
        mask = (pid == pid_value).to_numpy()

        main_candidates = []
        for sv in s_img[mask]:
            main_candidates.extend(extract_bracket_items(sv))
        main_candidates = [x for x in main_candidates if x]

        detail_candidates = []
        for tv in t_img[mask]:
            detail_candidates.extend(extract_bracket_items(tv))
        detail_candidates = uniq_keep_order([x for x in detail_candidates if x])

        return main_candidates, detail_candidates

    # ê³„ì‚°ìš© (ëŒ€í‘œí–‰)
    h_num = pd.to_numeric(a_rep.iloc[:, col_idx("H")], errors="coerce").fillna(0).to_numpy()
    j_num = pd.to_numeric(a_rep.iloc[:, col_idx("J")], errors="coerce").fillna(0).to_numpy()

    out_rows = []
    for i in range(len(a_rep)):
        pid_i = pid_rep.iloc[i]
        is_option = pid_i in option_pids

        row = {}
        row["A"] = 1
        row["B"] = 217089
        row["C"] = 1011307
        row["J"] = "n"

        # ìƒí’ˆëª…
        row["G"] = a_rep.iloc[:, col_idx("D")].to_numpy()[i]

        # S = A:H
        row["S"] = a_rep.iloc[:, col_idx("H")].to_numpy()[i]

        # T = (H - J) + "-1"
        row["T"] = f"{int(h_num[i] - j_num[i])}-1"

        # AU = í•­ìƒ ë¹ˆì¹¸
        row["AU"] = ""

        # AR/AS = A:C (ì—†ìœ¼ë©´ ë¹ˆì¹¸)
        c_raw = a_rep.iloc[:, col_idx("C")].to_numpy()[i]
        c_str = "" if pd.isna(c_raw) or str(c_raw).strip().lower() == "nan" or str(c_raw).strip() == "" else c_raw
        row["AR"] = c_str
        row["AS"] = c_str

        # íŒë§¤ì¢…ë£Œì¼: ê·¸ë£¹ ìµœì†Œê°’
        pmin = p_min_map.get(pid_i, pd.NaT)
        if pd.isna(pmin):
            row["M"] = 1
            row["O"] = "2999-12-31"   # OëŠ” ê¸°ì¡´ ê·œì¹™ ìœ ì§€
            row["AP"] = ""            # âœ… ë³€ê²½: P ì—†ìœ¼ë©´ APëŠ” ë¹ˆì¹¸
        else:
            d = pd.Timestamp(pmin).strftime("%Y-%m-%d")
            row["M"] = 2
            row["O"] = d
            row["AP"] = d            # ë‚ ì§œë§Œ

        # AW ì´ë¯¸ì§€
        main_items, detail_items = group_images(pid_i)
        row["AW"] = build_aw_cell(main_items, detail_items)

        # âœ… ë¹„ì˜µì…˜ ì¬ê³ : W = A:M
        if not is_option:
            w_raw = a_rep.iloc[:, col_idx("M")].to_numpy()[i]
            row["W"] = "" if pd.isna(w_raw) else w_raw

        # ì˜µì…˜ ì²˜ë¦¬
        if is_option:
            row["AB"] = "y"
            row["AC"] = "ì„ íƒ"
            row["AD"] = opt_value_map.get(pid_i, "")
            row["AG"] = opt_stock_map.get(pid_i, "")

        out_rows.append(row)

    return out_rows


# =========================
# Streamlit UI
# =========================
st.set_page_config(page_title="Aâ†’B ë³€í™˜ê¸°(ìµœì¢…)", layout="wide")
st.title("ğŸ“¦ AíŒŒì¼ â†’ Bí…œí”Œë¦¿(b.xlsx) ìë™ ë³€í™˜ê¸° (ìµœì¢…)")

with st.expander("ë™ì‘ ìš”ì•½", expanded=True):
    st.write(
        "- í…œí”Œë¦¿ ì—…ë¡œë“œ ì—†ì´ë„ **ê°™ì€ í´ë”ì˜ b.xlsxë¥¼ ìë™ ì‚¬ìš©**í•©ë‹ˆë‹¤.\n"
        "- ì¶œë ¥ íŒŒì¼(ì§€ì • ì‹œíŠ¸)ì—ì„œë§Œ **1,3,4,5,6í–‰ ì‚­ì œ**í•˜ê³  **2í–‰(ì»¬ëŸ¼ëª…)ì€ ìœ ì§€**í•©ë‹ˆë‹¤.\n"
        "- **APëŠ” Pê°€ ì—†ìœ¼ë©´ ë¹ˆì¹¸**, **AUëŠ” í•­ìƒ ë¹ˆì¹¸**, **Cê°€ ì—†ìœ¼ë©´ AR/ASëŠ” ë¹ˆì¹¸**ì…ë‹ˆë‹¤.\n"
        "- ë¹„ì˜µì…˜ì€ **W=ì¬ê³ **, ì˜µì…˜ì€ **AG=ì˜µì…˜ì¬ê³ (^|^)** ì…ë‹ˆë‹¤.\n"
    )

st.sidebar.header("ì„¤ì •")
id_col_letter = st.sidebar.text_input("AíŒŒì¼ ìƒí’ˆì•„ì´ë”” ì»¬ëŸ¼(ì—‘ì…€ ë¬¸ì)", value=DEFAULT_ID_COL).strip().upper()
chunk_size = st.sidebar.number_input("ë¶„í•  ì €ì¥(í–‰)", min_value=10, max_value=5000, value=DEFAULT_CHUNK, step=10)
sheet_index = st.sidebar.number_input("í…œí”Œë¦¿ì— ì“¸ ì‹œíŠ¸ ì¸ë±ìŠ¤(0=ì²« ì‹œíŠ¸)", min_value=0, max_value=30, value=DEFAULT_OUT_SHEET_INDEX, step=1)

template_file = st.file_uploader("B í…œí”Œë¦¿ ì—…ë¡œë“œ(ì„ íƒ)", type=["xlsx"])
a_files = st.file_uploader("AíŒŒì¼ ì—…ë¡œë“œ(ì—¬ëŸ¬ ê°œ ê°€ëŠ¥)", type=["xlsx"], accept_multiple_files=True)

run_btn = st.button("ğŸš€ ë³€í™˜ ì‹œì‘", disabled=not a_files)

if run_btn:
    t0 = time.time()
    st.info("ì²˜ë¦¬ ì¤‘...")

    try:
        template_bytes = get_template_bytes(template_file)
    except Exception as e:
        st.error(str(e))
        st.stop()

    summary_rows = []
    error_rows = []

    zip_buf = BytesIO()
    with zipfile.ZipFile(zip_buf, "w", zipfile.ZIP_DEFLATED) as zf:
        for uf in a_files:
            if uf.name.startswith("~$"):
                continue

            started = time.time()
            status = "OK"
            msg = ""
            input_rows = 0
            out_files = 0

            try:
                a_df = pd.read_excel(uf)
                input_rows = len(a_df)

                ok, vmsg = validate_a_df(a_df, id_col_letter)
                if not ok:
                    raise ValueError(vmsg)

                rows = make_b_rows_from_a(a_df, id_col_letter)
                chunks = split_rows(rows, int(chunk_size))

                for idx, chunk in enumerate(chunks, start=1):
                    out_xlsx = apply_rows_to_template(
                        template_bytes=template_bytes,
                        rows=chunk,
                        sheet_index=int(sheet_index),
                        start_row_after_header=2  # ì»¬ëŸ¼ëª… ì•„ë˜ë¡œ ì…ë ¥
                    )
                    out_name = f"{Path(uf.name).stem}_part{idx:03d}.xlsx"
                    zf.writestr(out_name, out_xlsx)
                    out_files += 1

            except Exception as e:
                status = "FAIL"
                msg = str(e)
                error_rows.append({"file": uf.name, "reason": msg})

            elapsed = round(time.time() - started, 3)
            summary_rows.append({
                "file": uf.name,
                "status": status,
                "input_rows": input_rows,
                "output_files": out_files,
                "seconds": elapsed,
                "message": msg
            })

        summary_df = pd.DataFrame(summary_rows)
        zf.writestr("summary_report.csv", summary_df.to_csv(index=False).encode("utf-8-sig"))

        if error_rows:
            errors_df = pd.DataFrame(error_rows)
            zf.writestr("errors.csv", errors_df.to_csv(index=False).encode("utf-8-sig"))

    zip_buf.seek(0)
    total_sec = round(time.time() - t0, 2)

    st.success(f"âœ… ì™„ë£Œ! ì´ ì†Œìš” {total_sec}s")
    st.subheader("ğŸ“Š ìš”ì•½ ë¦¬í¬íŠ¸")
    st.dataframe(pd.DataFrame(summary_rows), use_container_width=True)

    if error_rows:
        st.subheader("âš ï¸ ì—ëŸ¬")
        st.dataframe(pd.DataFrame(error_rows), use_container_width=True)

    st.download_button(
        "ğŸ“¦ ê²°ê³¼ ZIP ë‹¤ìš´ë¡œë“œ",
        data=zip_buf,
        file_name="B_result.zip",
        mime="application/zip"
    )
